{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>1. MEU PRIMEIRO SCRAPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Web Scraping* é o termo utilizado para definir a prática de coletar automaticamente informações na Internet. Isto é feito, geralmente, por meio de programas que simulam a navegação humana na Web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Ambiente e bibliotecas\n",
    "### Utilizaremos em nosso treinamento o navegador Google Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9pXIMIWByAp"
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "import urllib.request as urllib_request\n",
    "import pandas\n",
    "\n",
    "print(\"BeautifulSoup ->\", bs4.__version__)\n",
    "print(\"urllib ->\", urllib_request.__version__)\n",
    "print(\"pandas ->\", pandas.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3. Meu primeiro scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requisitar no servidor para acessar a página todo o 'código fonte'\n",
    "from urllib.request import urlopen\n",
    "#Transforma a resposta da página para que possamos acessar de fato de forma fácil\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://alura-site-scraping.herokuapp.com/hello-world.php'\n",
    "\n",
    "response = urlopen(url)\n",
    "html = response.read()\n",
    "#O Parser é o que possibilita pegar o arquivo html e entender(interpretar) o que é uma tag, classe etc\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "print(soup.find('h1', id=\"hello-world\").get_text())\n",
    "print(soup.find('p').get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <font color=green>2. OBTENDO E TRATANDO O CONTEÚDO DE UM HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1. Entendendo a web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./web/web.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2. Obtendo o conteúdo HTML de um site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# urllib.request\n",
    "## https://docs.python.org/3/library/urllib.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "c1pKGnTpgvFU",
    "outputId": "b6b7e32d-4c3e-4f52-a8ba-0b1cbfe15ea4"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "url = 'https://alura-site-scraping.herokuapp.com/index.php'\n",
    "\n",
    "response = urlopen(url)\n",
    "html = response.read()\n",
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://docs.python.org/3/library/urllib.request.html#urllib.request.Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "\n",
    "url = 'https://www.alura.com.br'\n",
    "#F12 -> Network -> index -> Request Headers -> User-Agent\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36'}\n",
    "\n",
    "try:\n",
    "    req = Request(url, headers = headers)\n",
    "    response = urlopen(req)\n",
    "    print(response.read())\n",
    "    \n",
    "except HTTPError as e:\n",
    "    print(e.status, e.reason)\n",
    "    \n",
    "except URLError as e:\n",
    "    print(e.reason)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3. Tratamento de string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "url = 'https://alura-site-scraping.herokuapp.com/index.php'\n",
    "\n",
    "response = urlopen(url)\n",
    "html = response.read()\n",
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertando o tipo bytes para string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = html.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando os caracteres de tabulação, quebra de linha etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Unir todo o html agora sem o /z /n etc\n",
    "\" \".join(html.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando os espaços em branco entre as TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\" \".join(html.split()).replace('> <', '><')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de tratamento de strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_html(input):\n",
    "    return \" \".join(input.split()).replace('> <', '><')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "html = trata_html(html)\n",
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsfhL3sZFRZu"
   },
   "source": [
    "---\n",
    "# <font color=green>3. INTRODUÇÃO AO BEAUTIFULSOUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsfhL3sZFRZu"
   },
   "source": [
    "# 3.1. HTML da nossa página"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HTML** (*HyperText Markup Language*) é uma linguagem de marcação composta por **tags** que deteminam o papel que cada parte do documento vai assumir. As **tags** são formadas pelo seu nome e atributos. Os atributos servem para configurar e também modificar as características padrões de uma **tag**.\n",
    "\n",
    "## Estrutura básica\n",
    "\n",
    "```html\n",
    "<html>\n",
    "    <head>\n",
    "        <meta charset=\"utf-8\" />\n",
    "        <title>Alura Motors</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div id=\"container\">\n",
    "            <h1>Alura</h1>\n",
    "            <h2 class=\"formato\">Cursos de Tecnologia</h2>\n",
    "            <p>Você vai estudar, praticar, discutir e aprender.</p>\n",
    "            <a href=\"https://www.alura.com.br/\">Clique aqui</a>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "```<html>``` - determina o início do documento.\n",
    "\n",
    "```<head>``` - cabeçalho. Contém informações e configurações do documento.\n",
    "\n",
    "```<body>``` - é o corpo do documento, onde todo o conteúdo é colocado. Esta é a parte visível em um navegador.\n",
    "\n",
    "## Tags mais comuns\n",
    "\n",
    "```<div>``` - define uma divisão da página. Pode ser formatada de diversas maneiras.\n",
    "\n",
    "```<h1>, <h2>, <h3>, <h4>, <h5>, <h6>``` - marcadores de títulos.\n",
    "\n",
    "```<p>``` - marcador de parágrafo.\n",
    "\n",
    "```<a>``` - hiperlink.\n",
    "\n",
    "```<img>``` - exibição de imagens.\n",
    "\n",
    "```<table>``` - definição de tabelas.\n",
    "\n",
    "```<ul>, <li>``` - definição de listas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2. Criando um objeto BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://www.crummy.com/software/BeautifulSoup/\n",
    "\n",
    "### Sobre parser ver: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#parser-installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "5Oxx_d0BCWGa",
    "outputId": "4d2c4e2b-57fe-413d-9521-91711e0e5fdc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prettify -> Formatação HTML\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3. Acessando tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.html.head.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.div.div.div.div.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4. Acessando o conteúdo das tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.h5.getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strip: Remove os espaços em branco do início e do fim de cada bloco de texto retornado\n",
    "soup.get_text(separator=' || ', strip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5. Acessando os atributos de uma tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.img.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.img.attrs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.img.attrs.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.img['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.img.get('src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <font color=green>4. PESQUISANDO COM O BEAUTIFULSOUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1. Os métodos *find()* e *findAll()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### *find(tag, attributes, recursive, text, **kwargs)*\n",
    "\n",
    "- ### *findAll(tag, attributes, recursive, text, limit, **kwargs)*\n",
    "\n",
    "#### https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find\n",
    "#### https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all\n",
    "\n",
    "> **Observação:**\n",
    "> - *findAll()* também pode ser utilizado como *find_all()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método *find()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método *findAll()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comando equivalente ao método *find()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('img',limit=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atalho para o método *findAll()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup('img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passando listas de TAGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(['h1','h2','h3','h4','h5','h6'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando o argumento *attributes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.findAll('p',{\"class\":\"txt-value\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscando por conteúdo de uma TAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll('p',text=\"Belo Horizonte - MG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando diretamente os atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll('img',alt='Foto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in soup.findAll('img',alt='Foto'):\n",
    "    print(item.get('src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuidado com o atributo \"class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('p',class_=\"txt-value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtendo todo o conteúdo de texto de uma página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2. Outros métodos de pesquisa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### *findParent(tag, attributes, text, **kwargs)*\n",
    "\n",
    "- ### *findParents(tag, attributes, text, limit, **kwargs)*\n",
    "\n",
    "#### https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-parents-and-find-parent\n",
    "\n",
    "> **Observação:**\n",
    "> - *findParent()* e *findParents()* também podem ser utilizados como *find_parent()* e *find_parents()*, respectivamente.\n",
    "---\n",
    "- ### *findNextSibling(tag, attributes, text, **kwargs)*\n",
    "\n",
    "- ### *findNextSiblings(tag, attributes, text, limit, **kwargs)*\n",
    "\n",
    "- ### *findPreviousSibling(tag, attributes, text, **kwargs)*\n",
    "\n",
    "- ### *findPreviousSiblings(tag, attributes, text, limit, **kwargs)*\n",
    "\n",
    "#### https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-next-siblings-and-find-next-sibling\n",
    "#### https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-previous-siblings-and-find-previous-sibling\n",
    "\n",
    "> **Observação:**\n",
    "> - *findNextSibling()*, *findNextSiblings()*, *findPreviousSibling()* e *findPreviousSiblings()* também podem ser utilizados como *find_next_sibling()*, *find_next_siblings()*, *find_previous_sibling()* e *find_previous_siblings()*, respectivamente.\n",
    "---\n",
    "- ### *findNext(tag, attributes, text, **kwargs)*\n",
    "\n",
    "- ### *findAllNext(tag, attributes, text, limit, **kwargs)*\n",
    "\n",
    "- ### *findPrevious(tag, attributes, text, **kwargs)*\n",
    "\n",
    "- ### *findAllPrevious(tag, attributes, text, limit, **kwargs)*\n",
    "\n",
    "#### https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all-next-and-find-next\n",
    "#### https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all-previous-and-find-previous\n",
    "\n",
    "> **Observação:**\n",
    "> - *findNext()*, *findAllNext()*, *findPrevious* e *findAllPrevious* também podem ser utilizados como *find_next()*, *find_all_next()*, *find_previous()* e *find_all_previous()*, respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML de exemplo para ilustrar a utilização dos métodos de pesquisa do BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://caelum-online-public.s3.amazonaws.com/1381-scraping/01/BeautifulSoup-method.png\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <div id=“container-a”>\n",
    "            <h1>Título A</h1>\n",
    "            <h2 class=\"ref-a\">Sub título A</h2>\n",
    "            <p>Texto de conteúdo A</p>\n",
    "        </div>\n",
    "        <div id=“container-b”>\n",
    "            <h1>Título B</h1>\n",
    "            <h2 class=\"ref-b\">Sub título B</h2>\n",
    "            <p>Texto de conteúdo B</p>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_teste = \"\"\"\n",
    "    <html>\n",
    "        <body>\n",
    "            <div id=\"container-a\">\n",
    "                <h1>Título A</h1>\n",
    "                <h2 class=\"ref-a\">Sub título A</h2>\n",
    "                <p>Texto de conteúdo A</p>\n",
    "            </div>\n",
    "            <div id=\"container-b\">\n",
    "                <h1>Título B</h1>\n",
    "                <h2 class=\"ref-b\">Sub título B</h2>\n",
    "                <p>Texto de conteúdo B</p>\n",
    "            </div>\n",
    "        </body>\n",
    "    </html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamentos para a string HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_teste = trata_html(html_teste)\n",
    "html_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o objeto BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_teste, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2').find_parent('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2').find_parents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in soup.findAll('h2'):\n",
    "    print(item.find_parent('div'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siblings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2').findNextSibling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2').findPreviousSibling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('p').findPreviousSiblings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next e Previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2').findNext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2').findPrevious()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2').findAllNext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>5. WEB SCRAPING DO SITE ALURA MOTORS - OBTENDO OS DADOS DE UM ANÚNCIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1. Identificando e selecionando os dados no HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtendo o HTML e criando o objeto BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = urlopen('https://alura-site-scraping.herokuapp.com/index.php')\n",
    "html = response.read().decode('utf-8')\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando variávels para armazenar informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = []\n",
    "card = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtendo os dados do primeiro CARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "anuncio = soup.find('div',{'class':'well card'})\n",
    "anuncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2. Obtendo o VALOR do veículo anunciado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card['value'] = anuncio.find('p',{'class':'txt-value'}).getText()\n",
    "card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3. Obtendo as INFORMAÇÕES sobre o veículo anunciado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = anuncio.find('div',{'class':'body-card'}).findAll('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for info in infos:\n",
    "    card[info.get('class')[0].split('-')[-1]] = info.get_text()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4. Obtendo os ACESSÓRIOS do veículo anunciado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = anuncio.find('div',{'class':'body-card'}).find('ul').findAll('li')\n",
    "items.pop()\n",
    "acessorios = []\n",
    "for item in items:\n",
    "    acessorios.append(item.getText().replace('► ', ''))\n",
    "card['items'] = acessorios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.5 Criando um DataFrame com os dados coletados do Alura Motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padrao de orientação nao deve ser colunas, mas linhas\n",
    "dataset = pd.DataFrame.from_dict(card,orient='index').T\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.6. Obtendo a FOTO do anúncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = anuncio.find('div',{'class':'image-card'}).img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.get('src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotina para acessar e salvar a FOTO do anúncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://docs.python.org/3/library/urllib.request.html#urllib.request.urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "urlretrieve(image.get('src'),'./output/img/'+ image.get('src').split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>6. WEB SCRAPING DO SITE ALURA MOTORS - OBTENDO OS DADOS DE TODOS OS ANÚNCIOS DE UMA PÁGINA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1. Identificando as informações no HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anuncios = soup.find('div',{'id':'container-cards'}).findAll('div',class_='card')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for anuncio in anuncios:\n",
    "    print(str(anuncio)+\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2. Criando uma rotina de scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>motor</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>items</th>\n",
       "      <th>opportunity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R$ 338.000</td>\n",
       "      <td>LAMBORGHINI AVENTADOR</td>\n",
       "      <td>USADO</td>\n",
       "      <td>Motor 1.8 16v</td>\n",
       "      <td>Ano 1993 - 55.286 km</td>\n",
       "      <td>Belo Horizonte - MG</td>\n",
       "      <td>[4 X 4, Câmera de estacionamento, Controle de ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R$ 346.000</td>\n",
       "      <td>BMW M2</td>\n",
       "      <td>USADO</td>\n",
       "      <td>Motor 3.0 32v</td>\n",
       "      <td>Ano 2018 - 83.447 km</td>\n",
       "      <td>Belo Horizonte - MG</td>\n",
       "      <td>[Câmera de estacionamento, Controle de estabil...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R$ 480.000</td>\n",
       "      <td>ALFA</td>\n",
       "      <td>USADO</td>\n",
       "      <td>Motor 1.8 16v</td>\n",
       "      <td>Ano 2004 - 19.722 km</td>\n",
       "      <td>Rio de Janeiro - RJ</td>\n",
       "      <td>[Central multimídia, Bancos de couro, Rodas de...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R$ 133.000</td>\n",
       "      <td>PUECH</td>\n",
       "      <td>USADO</td>\n",
       "      <td>Motor Diesel V8</td>\n",
       "      <td>Ano 1992 - 34.335 km</td>\n",
       "      <td>São Paulo - SP</td>\n",
       "      <td>[Bancos de couro, Freios ABS, Rodas de liga, C...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R$ 175.000</td>\n",
       "      <td>LAMBORGHINI MURCIELAGO</td>\n",
       "      <td>USADO</td>\n",
       "      <td>Motor 1.0 8v</td>\n",
       "      <td>Ano 1991 - 464 km</td>\n",
       "      <td>Belo Horizonte - MG</td>\n",
       "      <td>[Central multimídia, Teto panorâmico, Sensor c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R$ 239.000</td>\n",
       "      <td>ASTON MARTIN</td>\n",
       "      <td>USADO</td>\n",
       "      <td>Motor Diesel V6</td>\n",
       "      <td>Ano 2004 - 50.189 km</td>\n",
       "      <td>Belo Horizonte - MG</td>\n",
       "      <td>[Painel digital, Controle de tração, Teto pano...</td>\n",
       "      <td>OPORTUNIDADE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R$ 115.000</td>\n",
       "      <td>TVR</td>\n",
       "      <td>USADO</td>\n",
       "      <td>Motor 4.0 Turbo</td>\n",
       "      <td>Ano 2014 - 17.778 km</td>\n",
       "      <td>Belo Horizonte - MG</td>\n",
       "      <td>[4 X 4, Teto panorâmico, Central multimídia, C...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>R$ 114.000</td>\n",
       "      <td>EXCALIBUR</td>\n",
       "      <td>USADO</td>\n",
       "      <td>Motor 3.0 32v</td>\n",
       "      <td>Ano 2009 - 81.251 km</td>\n",
       "      <td>Rio de Janeiro - RJ</td>\n",
       "      <td>[Painel digital, Câmbio automático, Sensor de ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>R$ 75.000</td>\n",
       "      <td>MCLAREN</td>\n",
       "      <td>NOVO</td>\n",
       "      <td>Motor Diesel</td>\n",
       "      <td>Ano 2019 - 0 km</td>\n",
       "      <td>São Paulo - SP</td>\n",
       "      <td>[Central multimídia, Câmera de estacionamento,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>R$ 117.000</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>USADO</td>\n",
       "      <td>Motor 4.0 Turbo</td>\n",
       "      <td>Ano 1999 - 12.536 km</td>\n",
       "      <td>São Paulo - SP</td>\n",
       "      <td>[Bancos de couro, Freios ABS, Piloto automátic...</td>\n",
       "      <td>OPORTUNIDADE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        value                    name category            motor  \\\n",
       "0  R$ 338.000   LAMBORGHINI AVENTADOR    USADO    Motor 1.8 16v   \n",
       "1  R$ 346.000                  BMW M2    USADO    Motor 3.0 32v   \n",
       "2  R$ 480.000                    ALFA    USADO    Motor 1.8 16v   \n",
       "3  R$ 133.000                   PUECH    USADO  Motor Diesel V8   \n",
       "4  R$ 175.000  LAMBORGHINI MURCIELAGO    USADO     Motor 1.0 8v   \n",
       "5  R$ 239.000            ASTON MARTIN    USADO  Motor Diesel V6   \n",
       "6  R$ 115.000                     TVR    USADO  Motor 4.0 Turbo   \n",
       "7  R$ 114.000               EXCALIBUR    USADO    Motor 3.0 32v   \n",
       "8   R$ 75.000                 MCLAREN     NOVO     Motor Diesel   \n",
       "9  R$ 117.000                  TOYOTA    USADO  Motor 4.0 Turbo   \n",
       "\n",
       "            description             location  \\\n",
       "0  Ano 1993 - 55.286 km  Belo Horizonte - MG   \n",
       "1  Ano 2018 - 83.447 km  Belo Horizonte - MG   \n",
       "2  Ano 2004 - 19.722 km  Rio de Janeiro - RJ   \n",
       "3  Ano 1992 - 34.335 km       São Paulo - SP   \n",
       "4     Ano 1991 - 464 km  Belo Horizonte - MG   \n",
       "5  Ano 2004 - 50.189 km  Belo Horizonte - MG   \n",
       "6  Ano 2014 - 17.778 km  Belo Horizonte - MG   \n",
       "7  Ano 2009 - 81.251 km  Rio de Janeiro - RJ   \n",
       "8       Ano 2019 - 0 km       São Paulo - SP   \n",
       "9  Ano 1999 - 12.536 km       São Paulo - SP   \n",
       "\n",
       "                                               items   opportunity  \n",
       "0  [4 X 4, Câmera de estacionamento, Controle de ...           NaN  \n",
       "1  [Câmera de estacionamento, Controle de estabil...           NaN  \n",
       "2  [Central multimídia, Bancos de couro, Rodas de...           NaN  \n",
       "3  [Bancos de couro, Freios ABS, Rodas de liga, C...           NaN  \n",
       "4  [Central multimídia, Teto panorâmico, Sensor c...           NaN  \n",
       "5  [Painel digital, Controle de tração, Teto pano...  OPORTUNIDADE  \n",
       "6  [4 X 4, Teto panorâmico, Central multimídia, C...           NaN  \n",
       "7  [Painel digital, Câmbio automático, Sensor de ...           NaN  \n",
       "8  [Central multimídia, Câmera de estacionamento,...           NaN  \n",
       "9  [Bancos de couro, Freios ABS, Piloto automátic...  OPORTUNIDADE  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando bibliotecas\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Declarando variável cards\n",
    "cards = []\n",
    "# Obtendo o HTML\n",
    "response = urlopen('https://alura-site-scraping.herokuapp.com/index.php')\n",
    "html = response.read().decode('utf-8')\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Obtendo as TAGs de interesse\n",
    "anuncios = soup.find('div',{'id':'container-cards'}).findAll('div',class_='card')\n",
    "# Coletando as informações dos cards\n",
    "for anuncio in anuncios:\n",
    "    card = {}\n",
    "\n",
    "    #Valor\n",
    "    card['value'] = anuncio.find('p',{'class':'txt-value'}).getText()\n",
    "\n",
    "    #Informações\n",
    "    infos = anuncio.find('div',{'class':'body-card'}).findAll('p')\n",
    "    for info in infos:\n",
    "        card[info.get('class')[0].split('-')[-1]] = info.get_text()\n",
    "        \n",
    "    #Acessórios\n",
    "    items = anuncio.find('div',{'class':'body-card'}).find('ul').findAll('li')\n",
    "    items.pop()\n",
    "    acessorios = []\n",
    "    for item in items:\n",
    "        acessorios.append(item.getText().replace('► ', ''))\n",
    "    card['items'] = acessorios\n",
    "\n",
    "    # Adicionando resultado à lista cards\n",
    "    cards.append(card)\n",
    "\n",
    "    #Imagens\n",
    "    image = anuncio.find('div',{'class':'image-card'}).img\n",
    "    urlretrieve(image.get('src'),'./output/img/'+ image.get('src').split('/')[-1])\n",
    "\n",
    "\n",
    "\n",
    "# Criando um DataFrame com os resultados\n",
    "dataset = pd.DataFrame(cards)\n",
    "dataset.to_csv('./output/data/dataset.csv', sep=';', index = False, encoding = 'utf-8-sig')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>7. WEB SCRAPING DO SITE ALURA MOTORS - OBTENDO OS DADOS DE TODOS OS ANÚNCIOS DO SITE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1. Identificando as informações no HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2. Criando uma rotina de scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled12.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f1b78eb436411a9c3c2406ff65dd6a2a483e2b78ec2ae8c1343ef3e593983b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
